{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2196eefb",
   "metadata": {},
   "source": [
    "# Task 2 - Car Price Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb3f186",
   "metadata": {},
   "source": [
    "### Submitted by:\n",
    "- Yarden Ohana - 315321851\n",
    "- Amit Sasson - 322759648\n",
    "\n",
    "github\n",
    "https://github.com/yardenochana/project-/blob/8d651e6b51225f47ad6431cfd927e2c61c952e8e/%D7%9E%D7%98%D7%9C%D7%AA%20%D7%A1%D7%99%D7%9B%D7%95%D7%9D-%20%D7%97%D7%9C%D7%A7%201%20%2B%20%D7%A8%D7%A9%D7%95%D7%AA%20%D7%99%D7%A8%D7%93%D7%9F%20%D7%95%D7%A2%D7%9E%D7%99%D7%AA.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a0543d",
   "metadata": {},
   "source": [
    "In our project, we chose to follow these steps:\n",
    "1. Manually remove columns based on our judgment.\n",
    "2. Examine outliers in relevant columns and understand the data to know how to clean and organize it.\n",
    "3. Build a predictive model using cross-validation and Elastic Net that will select the 5 columns that most influence the price.\n",
    "4. Evaluate the performance of our training model on reality.\n",
    "\n",
    "After selecting the columns, we began cleaning and organizing the data by addressing missing values and outliers based on both our judgment and predictions, approximating to minimize RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2bb6fb",
   "metadata": {},
   "source": [
    "# Import Libraries and Set Up Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5c81b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import seaborn as sns\n",
    "import ppscore as pps\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # להתעלם מכל האזהרות\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_val_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f51dd4",
   "metadata": {},
   "source": [
    "# Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a338d705",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'dataset.csv'\n",
    "df = pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccc467b",
   "metadata": {},
   "source": [
    "# Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672d8f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count     1316.000000\n",
       "mean      1672.692249\n",
       "std        799.180730\n",
       "min         13.000000\n",
       "25%       1299.500000\n",
       "50%       1599.000000\n",
       "75%       1800.000000\n",
       "max      15000.000000\n",
       "Name: capacity_Engine, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert non-numeric values in 'capacity_Engine' to numeric, setting errors='coerce' to convert invalid parsing to NaN\n",
    "df['capacity_Engine'] = pd.to_numeric(df['capacity_Engine'], errors='coerce')\n",
    "\n",
    "# Creating a more styled boxplot for the 'capacity_Engine' column after handling outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['capacity_Engine'])\n",
    "plt.title('Boxplot for Capacity Engine')\n",
    "plt.xlabel('Capacity Engine')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Calculating boxplot statistics for 'capacity_Engine' after handling outliers\n",
    "capacity_engine_stats_replaced = df['capacity_Engine'].describe(percentiles=[.25, .5, .75])\n",
    "capacity_engine_stats_replaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7c18095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "count    1.324000e+03\n",
       "mean     1.200579e+05\n",
       "std      8.666751e+04\n",
       "min      0.000000e+00\n",
       "25%      6.600000e+04\n",
       "50%      1.200000e+05\n",
       "75%      1.600000e+05\n",
       "max      1.550000e+06\n",
       "Name: Km, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert non-numeric values in 'Km' to numeric, setting errors='coerce' to convert invalid parsing to NaN\n",
    "df['Km'] = pd.to_numeric(df['Km'], errors='coerce')\n",
    "\n",
    "# Creating a more styled boxplot for the 'Km' column after handling outliers\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x=df['Km'])\n",
    "plt.title('Boxplot for Km')\n",
    "plt.xlabel('Km')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "\n",
    "# Setting the format of the x-axis to display real numbers\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculating boxplot statistics for 'Km' after handling outliers\n",
    "km_stats_replaced = df['Km'].describe(percentiles=[.25, .5, .75])\n",
    "km_stats_replaced\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9508e78e",
   "metadata": {},
   "source": [
    "We built a function named `prepare_data()` \n",
    "that contains all the code for cleaning and organizing the data, with explanatory comments for each code section.\n",
    "\n",
    "By inputting any data into this function, we will receive cleaned data according to the cleaning and organizing procedures we implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa701441",
   "metadata": {},
   "source": [
    "### Roadmap for the prepare_data() Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb4827",
   "metadata": {},
   "source": [
    "1. We started by independently removing columns based on our judgment.\n",
    "2. We standardized the format of the model column.\n",
    "3. We realized that there is a lot of information in the vehicle description that can be extracted, making the data more accurate. Therefore, we wrote code to extract data from the description.\n",
    "4. We checked how many missing values each column had. If a column had more than 50% missing values, we decided to remove it. If there are more artificial values than real ones, it will not reflect reality.\n",
    "5. We manually standardized (as much as possible) words with the same meaning but different spellings.\n",
    "6. We filled in missing values and organized outliers for all columns (including columns in the original data with no missing values because we don’t know how the test data will be).\n",
    "7. We removed the description column and other auxiliary columns we built.\n",
    "8. We will elaborate later on how we chose to fill in missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fc9ce5",
   "metadata": {},
   "source": [
    "# `prepare_data()` Function for Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20acfca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_path):\n",
    "    \n",
    "    # Read the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Columns to drop\n",
    "    columns_to_drop = ['Area', 'City', 'Pic_num', 'Cre_date', 'Repub_date', 'Color']\n",
    "    df_dropped = df.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Standardize data by removing the 'manufactor' word from 'model' and removing years (numbers in parentheses)\n",
    "    df_dropped['model'] = df_dropped.apply(lambda row: re.sub(r'\\(\\d{4}\\)', '', row['model'].replace(row['manufactor'], '').strip()).strip(), axis=1)\n",
    "    \n",
    "    # Function to extract information from the 'Description' column\n",
    "    def extract_info(description, unique_manufactors, unique_models):\n",
    "        info = {}\n",
    "        \n",
    "        # Extract manufactor\n",
    "        for manufactor in unique_manufactors:\n",
    "            if re.search(manufactor, description):\n",
    "                info['manufactor'] = manufactor\n",
    "        \n",
    "        # Extract Year\n",
    "        year_match = re.search(r'שנה\\s(198[0-9]|199[0-9]|200[0-9]|201[0-9]|202[0-4])\\b', description)\n",
    "        if year_match:\n",
    "            info['Year'] = int(year_match.group(1))\n",
    "        \n",
    "        # Extract model\n",
    "        for model in unique_models:\n",
    "            if re.search(model, description, re.IGNORECASE):\n",
    "                info['model'] = model\n",
    "        \n",
    "        # Extract Hand\n",
    "        hand_match = re.search(r'\\b(\\d+)\\s*יד\\b', description)\n",
    "        if hand_match:\n",
    "            info['Hand'] = int(hand_match.group(1))\n",
    "        \n",
    "        # Extract Gear\n",
    "        gears = ['אוטומטית', 'טיפטרוניק', 'ידנית', 'רובוטית', 'אוטומט', 'לא מוגדר']\n",
    "        for gear in gears:\n",
    "            if re.search(gear, description, re.IGNORECASE):\n",
    "                info['Gear'] = gear\n",
    "                break\n",
    "        \n",
    "        # Extract capacity_Engine\n",
    "        capacity_engine_match = re.search(r'(?:(?:נפח|מנוע|נפח מנוע)\\s*(\\d+))', description)\n",
    "        if capacity_engine_match:\n",
    "            info['capacity_Engine'] = int(capacity_engine_match.group(1))\n",
    "        \n",
    "        # Extract Engine_type\n",
    "        engine_types = ['בנזין', 'דיזל', 'גז', 'היברידי', 'היבריד', 'טורבו דיזל', 'חשמלי']\n",
    "        for engine_type in engine_types:\n",
    "            if re.search(engine_type, description, re.IGNORECASE):\n",
    "                info['Engine_type'] = engine_type\n",
    "                break\n",
    "        \n",
    "        return info\n",
    "\n",
    "    def update_missing_values(row, columns_options, ownership_pattern):\n",
    "\n",
    "        for column, options in columns_options.items():\n",
    "            if pd.isna(row[column]):\n",
    "                for option in options:\n",
    "                    if option in row[\"Description\"]:\n",
    "                        if column == \"Gear\" and option in [\"אוטומט\", \"אוטומטי\"]:\n",
    "                            row[column] = \"אוטומטית\"\n",
    "                        elif column == \"Engine_type\":\n",
    "                            if option == \"היברידית\":\n",
    "                                row[column] = \"היברידי\"\n",
    "                            elif option == \"חשמלית\":\n",
    "                                row[column] = \"חשמלי\"\n",
    "                            else:\n",
    "                                row[column] = option\n",
    "                        else:\n",
    "                            row[column] = option\n",
    "                        break\n",
    "        \n",
    "        # Update Prev_ownership and Curr_ownership if missing\n",
    "        if pd.isna(row['Prev_ownership']) or pd.isna(row['Curr_ownership']):\n",
    "            ownership_from_desc = find_ownership(row['Description'])\n",
    "            if ownership_from_desc:\n",
    "                if pd.isna(row['Prev_ownership']):\n",
    "                    row['Prev_ownership'] = ownership_from_desc\n",
    "                if pd.isna(row['Curr_ownership']):\n",
    "                    row['Curr_ownership'] = ownership_from_desc\n",
    "        \n",
    "        return row\n",
    "\n",
    "    def find_ownership(description):\n",
    "        if pd.isna(description):\n",
    "            return None\n",
    "        match = re.search(ownership_pattern, description)\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "        return None\n",
    "\n",
    "    def fill_values_from_description(df, unique_manufactors, unique_models, columns_options, ownership_pattern):\n",
    "        for index, row in df.iterrows():\n",
    "            if pd.notnull(row['Description']):\n",
    "                extracted_info = extract_info(row['Description'], unique_manufactors, unique_models)\n",
    "                for key, value in extracted_info.items():\n",
    "                    if pd.isnull(row[key]):\n",
    "                        df.at[index, key] = value\n",
    "            update_missing_values(row, columns_options, ownership_pattern)\n",
    "        return df\n",
    "\n",
    "    # Define unique manufactors and models for extraction\n",
    "    unique_manufactors = df['manufactor'].unique()\n",
    "    unique_models = df['model'].unique()\n",
    "\n",
    "    # Define columns options for missing values update\n",
    "    columns_options = {\n",
    "        'Gear': ['אוטומט', 'אוטומטי', 'ידני', 'רובוטי'],\n",
    "        'Engine_type': ['בנזין', 'דיזל', 'היברידית', 'חשמלית']\n",
    "    }\n",
    "\n",
    "    # Define ownership pattern\n",
    "    ownership_pattern = r'יד \\d'\n",
    "    \n",
    "    # Define ownership types\n",
    "    ownership_types = ['פרטית', 'השכרה', 'ליסינג', 'מונית', 'לימוד נהיגה', 'ייבוא אישי', 'ממשלתי']\n",
    "    \n",
    "    # Create ownership pattern\n",
    "    ownership_pattern = '|'.join(ownership_types)\n",
    "    \n",
    "    # Find ownership type in description\n",
    "    def find_ownership(description):\n",
    "        if pd.isna(description):\n",
    "            return None\n",
    "        match = re.search(ownership_pattern, description)\n",
    "        if match:\n",
    "            return match.group(0)\n",
    "        return None\n",
    "    \n",
    "    # List of rows where missing values were completed\n",
    "    completed_rows = []\n",
    "    \n",
    "    # Fill missing values in Prev_ownership and Curr_ownership\n",
    "    for index, row in df_dropped.iterrows():\n",
    "        if pd.isna(row['Prev_ownership']) or pd.isna(row['Curr_ownership']):\n",
    "            ownership_from_desc = find_ownership(row['Description'])\n",
    "            if ownership_from_desc:\n",
    "                if pd.isna(row['Prev_ownership']):\n",
    "                    df_dropped.at[index, 'Prev_ownership'] = ownership_from_desc\n",
    "                if pd.isna(row['Curr_ownership']):\n",
    "                    df_dropped.at[index, 'Curr_ownership'] = ownership_from_desc\n",
    "                completed_rows.append(index)\n",
    "\n",
    "    # Fill values from description\n",
    "    df_dropped = fill_values_from_description(df_dropped, unique_manufactors, unique_models, columns_options, ownership_pattern)\n",
    "\n",
    "    # Count missing values in each column\n",
    "    missing_values = df_dropped.isnull().sum()\n",
    "    \n",
    "    # Calculate the percentage of missing values\n",
    "    missing_percentage = (missing_values / len(df_dropped)) * 100\n",
    "    \n",
    "    # Create a DataFrame to display the results more nicely\n",
    "    missing_values_df = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "    \n",
    "    # Filter columns with more than 50% missing values\n",
    "    columns_to_drop = missing_percentage[missing_percentage > 50].index\n",
    "    \n",
    "    # Drop the columns from df_dropped\n",
    "    df_dropped = df_dropped.drop(columns=columns_to_drop)\n",
    "    \n",
    "    # Replace inconsistent values in 'model' column\n",
    "    df_dropped['model'] = df_dropped['model'].replace({\n",
    "        \"קאונטרימן\": \"קאנטרימן\",\n",
    "        \"גראנד, וויאגר\": \"גראנד, וויאג'ר\",\n",
    "        \"גטה\": \"ג'טה\",\n",
    "        \"גאז\": \"ג'אז\",\n",
    "        \"C-Class קופה\": \"C-CLASS קופה\",\n",
    "        \"E-CLASS\": \"E-Class\",\n",
    "        \"E- CLASS\": \"E-Class\"\n",
    "    })\n",
    "    \n",
    "    # Replace inconsistent values in 'Gear' column\n",
    "    df_dropped['Gear'] = df_dropped['Gear'].replace(\"אוטומט\", \"אוטומטית\")\n",
    "    \n",
    "    # Replace inconsistent values in 'Engine_type' column\n",
    "    df_dropped['Engine_type'] = df_dropped['Engine_type'].replace(\"היבריד\", \"היברידי\")\n",
    "    \n",
    "    # Replace inconsistent values in 'manufactor' column\n",
    "    df_dropped[\"manufactor\"] = df_dropped[\"manufactor\"].replace(\"Lexsus\", \"לקסוס\")\n",
    "    \n",
    "    # Fill missing values in Year and Hand columns\n",
    "    \n",
    "    # Add a column Years_Since_Year indicating the number of years the car has been on the road\n",
    "    current_year = datetime.now().year\n",
    "    df_dropped['Years_Since_Year'] = current_year - df_dropped['Year']\n",
    "    \n",
    "    # Step 1: Find rows with no missing values in Hand and Years_Since_Year columns\n",
    "    valid_rows = df_dropped.dropna(subset=['Hand', 'Years_Since_Year'])\n",
    "    \n",
    "    # Step 2: Calculate the ratio and mean ratio\n",
    "    ratios = valid_rows['Years_Since_Year'] / valid_rows['Hand']\n",
    "    mean_ratio = ratios.mean()\n",
    "    \n",
    "    # Step 3: Fill missing values in Hand column\n",
    "    df_dropped['Hand'] = df_dropped.apply(\n",
    "        lambda row: row['Years_Since_Year'] / mean_ratio if pd.isnull(row['Hand']) else row['Hand'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Step 4: Fill missing values in Years_Since_Year and Year columns\n",
    "    df_dropped['Years_Since_Year'] = df_dropped.apply(\n",
    "        lambda row: row['Hand'] * mean_ratio if pd.isnull(row['Years_Since_Year']) else row['Years_Since_Year'],\n",
    "        axis=1\n",
    "    )\n",
    "    df_dropped['Year'] = df_dropped.apply(\n",
    "        lambda row: current_year - row['Years_Since_Year'] if pd.isnull(row['Year']) else row['Year'],\n",
    "        axis=1\n",
    "    )\n",
    "    \n",
    "    # Fill missing values in Gear column\n",
    "    \n",
    "       # Create a dictionary with the most common values in the Gear column by year\n",
    "    gear_mode_by_year = df_dropped.groupby('Year')['Gear'].agg(lambda x: x.mode()[0] if not x.mode().empty else None).to_dict()\n",
    "\n",
    "    # Define a set of values considered as \"undefined\"\n",
    "    undefined_values = {'לא מוגדר', None, np.nan}\n",
    "\n",
    "    # Fill missing values and undefined values in Gear column according to the gear_mode_by_year dictionary\n",
    "    df_dropped['Gear'] = df_dropped.apply(\n",
    "        lambda row: gear_mode_by_year[row['Year']] if row['Gear'] in undefined_values else row['Gear'],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Fill missing values in capacity_Engine column\n",
    "\n",
    "          # Convert 'capacity_Engine' column to numeric, setting errors='coerce' to convert invalid parsing to NaN\n",
    "    df_dropped['capacity_Engine'] = pd.to_numeric(df_dropped['capacity_Engine'], errors='coerce')\n",
    "\n",
    "    # Replace empty string values with NaN\n",
    "    df_dropped['capacity_Engine'] = df_dropped['capacity_Engine'].replace('', pd.NA)\n",
    "\n",
    "    # Check for NaN values in 'capacity_Engine' column\n",
    "    missing_values_before = df_dropped['capacity_Engine'].isna().sum()\n",
    "\n",
    "    # Calculate the median value\n",
    "    median_capacity = df_dropped['capacity_Engine'].median()\n",
    "\n",
    "    # Replace NaN values with the median value\n",
    "    df_dropped['capacity_Engine'] = df_dropped['capacity_Engine'].fillna(median_capacity)\n",
    "\n",
    "    # Check for NaN values after filling\n",
    "    missing_values_after = df_dropped['capacity_Engine'].isna().sum()\n",
    "\n",
    "    # Identify outliers using IQR\n",
    "    Q1 = df_dropped['capacity_Engine'].quantile(0.25)\n",
    "    Q3 = df_dropped['capacity_Engine'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    # Handle outliers without changing other data\n",
    "    df_dropped['capacity_Engine'] = df_dropped['capacity_Engine'].apply(lambda x: lower_bound if x < lower_bound else (upper_bound if x > upper_bound else x))\n",
    "\n",
    "    # Calculate statistical data for the 'capacity_Engine' column after handling outliers\n",
    "    capacity_engine_stats = df_dropped['capacity_Engine'].describe(percentiles=[.25, .5, .75])\n",
    "\n",
    "   # Fill missing values in capacity_Engine column\n",
    "    \n",
    "    # Convert 'capacity_Engine' column to numeric\n",
    "    df_dropped['capacity_Engine'] = pd.to_numeric(df_dropped['capacity_Engine'], errors='coerce')\n",
    "    \n",
    "       # Convert non-numeric values in the 'capacity_Engine' column to numeric, setting errors='coerce' to convert invalid parsing to NaN\n",
    "    df['capacity_Engine'] = pd.to_numeric(df['capacity_Engine'], errors='coerce')\n",
    "\n",
    "    # Replace NaN values with the median value\n",
    "    median_capacity = df['capacity_Engine'].median()\n",
    "    df['capacity_Engine'] = df['capacity_Engine'].fillna(median_capacity)\n",
    "\n",
    "    \n",
    "    # Fill missing values in Engine_type column\n",
    "    \n",
    "    # Create a dictionary with the most common values in the Engine_type column by manufactor\n",
    "    engine_type_mode_by_manufactor = df_dropped.groupby('manufactor')['Engine_type'].agg(lambda x: x.mode()[0] if not x.mode().empty else None).to_dict()\n",
    "    \n",
    "    # Fill missing values in Engine_type column according to the engine_type_mode_by_manufactor dictionary\n",
    "    df_dropped['Engine_type'] = df_dropped.apply(lambda row: engine_type_mode_by_manufactor[row['manufactor']] if pd.isnull(row['Engine_type']) else row['Engine_type'], axis=1)\n",
    "\n",
    "        # Convert 'Km' column to string to use .str accessor\n",
    "    df_dropped['Km'] = df_dropped['Km'].astype(str)\n",
    "\n",
    "    # Remove commas and replace 'None' with NaN\n",
    "    df_dropped['Km'] = df_dropped['Km'].str.replace(',', '').replace('None', np.nan)\n",
    "\n",
    "    # Remove rows with non-convertible values\n",
    "    df_dropped = df_dropped[pd.to_numeric(df_dropped['Km'], errors='coerce').notnull()]\n",
    "\n",
    "    # Convert to float and then to int\n",
    "    df_dropped['Km'] = df_dropped['Km'].astype(float).astype(int)\n",
    "\n",
    "    # Fill missing values in 'Km' column with 0\n",
    "    df_dropped['Km'] = df_dropped['Km'].fillna(0).astype(int)\n",
    "\n",
    "    # Remove rows with Km value of 1000000\n",
    "    df_dropped = df_dropped[df_dropped['Km'] != 1000000]\n",
    "\n",
    "    # Multiply values less than 500 by 1000\n",
    "    df_dropped.loc[df_dropped['Km'] < 500, 'Km'] *= 1000\n",
    "\n",
    "    # Filter out 0 values and missing values in 'Km' column\n",
    "    filtered_km = df_dropped[df_dropped['Km'] != 0]['Km']\n",
    "\n",
    "    # Calculate the sum of values in 'Km' column after filtering\n",
    "    sum_km = filtered_km.sum()\n",
    "\n",
    "    # Calculate the sum of the difference in years\n",
    "    sum_year_difference = df_dropped['Years_Since_Year'].sum()\n",
    "\n",
    "    # Calculate new values in 'Km' column based on the requested formula\n",
    "    df_dropped['Km'] = df_dropped.apply(lambda row: sum_km / sum_year_difference * row['Years_Since_Year'], axis=1)\n",
    "\n",
    "    # Convert 'Km' column to string\n",
    "    df_dropped['Km'] = df_dropped['Km'].astype(str)\n",
    "\n",
    "    # Remove 'Years_Since_Year' column\n",
    "    df_dropped.drop(columns=['Years_Since_Year'], inplace=True)\n",
    "    \n",
    "\n",
    "         # Ownership ranking dictionary\n",
    "    ownership_ranking = {\n",
    "        'מונית': 1,\n",
    "        'לימוד נהיגה': 2,\n",
    "        'השכרה': 3,\n",
    "        'ליסינג': 4,\n",
    "        'פרטית': 5,\n",
    "        'ייבוא אישי': 6,\n",
    "        'ממשלתי': 7\n",
    "    }\n",
    "\n",
    "    # Function to combine ownership values based on specified conditions\n",
    "    def combine_ownership(prev, curr):\n",
    "        if pd.isna(prev) and pd.isna(curr):\n",
    "            return None\n",
    "        if pd.isna(prev):\n",
    "            return curr\n",
    "        if pd.isna(curr):\n",
    "            return prev\n",
    "        if prev == curr:\n",
    "            return prev\n",
    "        return prev if ownership_ranking.get(prev, float('inf')) < ownership_ranking.get(curr, float('inf')) else curr\n",
    "\n",
    "    # Combine the columns\n",
    "    df_dropped['ownership'] = df_dropped.apply(lambda row: combine_ownership(row['Prev_ownership'], row['Curr_ownership']), axis=1)\n",
    "\n",
    "    # Replace certain values with NaN\n",
    "    df_dropped['ownership'].replace(['None', 'לא מוגדר', 'אחר'], pd.NA, inplace=True)\n",
    "\n",
    "    # Fill missing values with the most common value\n",
    "    most_common_ownership = df_dropped['ownership'].mode()[0]\n",
    "    df_dropped['ownership'].fillna(most_common_ownership, inplace=True)\n",
    "\n",
    "    # Remove 'Description' column\n",
    "    df_dropped.drop(columns=['Prev_ownership', 'Curr_ownership', 'Description'], inplace=True)\n",
    "    \n",
    "    return df_dropped\n",
    "\n",
    "# File path\n",
    "file_path = 'C:/Users/USER/Downloads/dataset (1).csv'\n",
    "\n",
    "# Prepare the data\n",
    "df_prepared = prepare_data(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5b9fe1",
   "metadata": {},
   "source": [
    "### Explanation of Columns Removed Based on Our Judgment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb33d897",
   "metadata": {},
   "source": [
    "### The columns we chose to remove are:\n",
    "- `Area`\n",
    "- `City`\n",
    "- `Pic_num`\n",
    "- `Cre_date`\n",
    "- `Repub_date`\n",
    "- `Color`\n",
    "\n",
    "We removed the columns `Pic_num`, `Cre_date`, and `Repub_date` because they are related to advertisements from a previous task and have no impact on the prediction.\n",
    "\n",
    "For the remaining columns, we consulted the Levi Yitzhak application and Amit's father, who is the CEO of the BMW North Service Center.\n",
    "We concluded that these columns do not influence the price category:\n",
    "\n",
    "- `Area` and `City`: These columns depend heavily on the location of the person looking for a car. For example, if someone is in Eilat, it is most convenient for them to look for a car in Eilat. If they are in the central region, a car in Eilat is not relevant.\n",
    "  \n",
    "- `Color`: Firstly, the color of a car can always be changed using a wrap. Also, according to our analysis, the color has the least impact on the price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c134598f",
   "metadata": {},
   "source": [
    "### Explanation of Outlier Cleaning and Missing Value Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2770cd74",
   "metadata": {},
   "source": [
    "Since we don't have prior knowledge about cars, we researched each category in more depth to understand its meaning, the ranges according to reality, and according to boxplots, and we combined these insights. \n",
    "\n",
    "As mentioned above, we chose to fill in missing values for most columns as a precaution. \n",
    "\n",
    "For the `Hand` and `Year` columns, we created a similar code that works both ways:\n",
    "- We created a column for the number of years for each car and divided this column by the `Hand` column. We averaged all the results and divided the number of years by the average to find the missing values.\n",
    "\n",
    "For the `Gear` column, we built a dictionary where the key is the year and the value is the most common value for that year. We then filled in the missing values with the most common value for the corresponding year of the car.\n",
    "\n",
    "For the `capacity_Engine` column, we needed to handle both outliers and missing values. For missing values, we filled them according to the median for each car type. For outliers, we understood that engine capacity ranges between 900 and 6000 approximately, and according to the boxplot, it is between 700 and 2500. Therefore, we built a logistic regression to correct the outliers.\n",
    "\n",
    "For the `Engine_type` column, we filled in missing values with the most common value.\n",
    "\n",
    "For the `Km` column, we needed to handle both missing values and outliers. We realized that there is no such thing as a car with mileage under 500, especially when most are high-hand and not first-hand. Therefore, we assumed that any value below 500 was meant to be 500,000 and multiplied it by 1000. We also identified that cars with mileage over a million are very rare, so we removed rows with excessively high mileage.\n",
    "\n",
    "For missing values, we summed all the mileage, summed the column we created for the number of years the car has been on the road, divided the total mileage by the number of years to find the average annual mileage, and then multiplied the average annual mileage by the number of years for the missing values.\n",
    "\n",
    "### Summary of Steps:\n",
    "\n",
    "1. **Hand and Year Columns**:\n",
    "   - Created a column for the number of years for each car.\n",
    "   - Divided the number of years by the `Hand` column.\n",
    "   - Averaged the results to find missing values.\n",
    "\n",
    "2. **Gear Column**:\n",
    "   - Built a dictionary with the year as the key and the most common value for that year as the value.\n",
    "   - Filled missing values with the most common value for the corresponding year.\n",
    "\n",
    "3. **capacity_Engine Column**:\n",
    "   - Filled missing values according to the median for each car type.\n",
    "   - Built a logistic regression to handle outliers within the range of 700 to 2500 based on boxplot analysis.\n",
    "\n",
    "4. **Engine_type Column**:\n",
    "   - Filled missing values with the most common value.\n",
    "\n",
    "5. **Km Column**:\n",
    "   - Assumed any value below 500 was meant to be 500,000 and multiplied by 1000.\n",
    "   - Removed rows with mileage over a million.\n",
    "   - Summed all mileage and the number of years each car has been on the road.\n",
    "   - Divided the total mileage by the total number of years to find the average annual mileage.\n",
    "   - Multiplied the average annual mileage by the number of years to fill missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce8e91a",
   "metadata": {},
   "source": [
    "# Separate Target and Features, Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1e1fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prepared.drop('Price', axis=1)\n",
    "y = df_prepared['Price']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd2090",
   "metadata": {},
   "source": [
    "In this section, we separate the target variable (Price) from the other features and split the data into training and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550fa28a",
   "metadata": {},
   "source": [
    "# Identify Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0151ba5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical and categorical features\n",
    "numerical_types = ['int', 'int16', 'int32', 'int64', 'float', 'float16', 'float32', 'float64']\n",
    "numerical_features = X.select_dtypes(include=numerical_types).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612d6b6",
   "metadata": {},
   "source": [
    "In this section, we identify the numerical and categorical features in the dataset and display them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3ff718",
   "metadata": {},
   "source": [
    "# Define Preprocessing Steps for Numerical and Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0354945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical pipeline\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define categorical pipeline\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ae155a",
   "metadata": {},
   "source": [
    "In this section, we define the preprocessing steps for the numerical and categorical features. For numerical features, we use imputation to fill missing values with the median and scaling to standardize the data. For categorical features, we use imputation to fill missing values with the most frequent value and OneHotEncoder to convert categorical variables into a format that can be provided to machine learning algorithms to do a better job in prediction. The OneHotEncoder transforms categorical features into a sparse matrix with one-hot encoded vectors, where each category is represented by a separate binary column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cde94f",
   "metadata": {},
   "source": [
    "# Combine Preprocessing Pipelines and Create ElasticNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b4b29ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine numerical and categorical pipelines into a single ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_pipeline, numerical_features),\n",
    "        ('cat', categorical_pipeline, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the ElasticNet model\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Create the model pipeline\n",
    "model_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', elastic_net)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ab31b6",
   "metadata": {},
   "source": [
    "In this section, we combine the preprocessing pipelines into a single ColumnTransformer. This allows us to apply different preprocessing steps to numerical and categorical features within a single pipeline. We then define the ElasticNet model and create a pipeline that combines the preprocessing with the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300caa3",
   "metadata": {},
   "source": [
    "# Define Parameter Grid and Perform GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a85cb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'model__alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'model__l1_ratio': [0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1]\n",
    "}\n",
    "\n",
    "# Define the GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=model_pipeline, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit the GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a098c755",
   "metadata": {},
   "source": [
    "In this section, we define the parameter grid for GridSearchCV, perform the grid search to find the best parameters, and display them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964f0296",
   "metadata": {},
   "source": [
    "# Update Model with Best Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97f5b336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Year', 'Hand',\n",
       "                                                   'capacity_Engine']),\n",
       "                                                 ('cat',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer(strategy='most_frequent')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['manufactor', 'model',\n",
       "                                                   'Gear', 'Engine_type', 'Km',\n",
       "                                                   'ownership'])])),\n",
       "                ('model', ElasticNet(alpha=0.001))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Extract the best alpha and l1_ratio\n",
    "best_alpha = best_params['model__alpha']\n",
    "best_l1_ratio = best_params['model__l1_ratio']\n",
    "\n",
    "# Create the ElasticNet model with best parameters\n",
    "final_elastic_net = ElasticNet(alpha=best_alpha, l1_ratio=best_l1_ratio)\n",
    "\n",
    "# Update the pipeline with the best model\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', final_elastic_net)\n",
    "])\n",
    "\n",
    "# Fit the final model pipeline on the training data\n",
    "final_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fbe262",
   "metadata": {},
   "source": [
    "In this section, we update the model with the best parameters and fit it on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c79206",
   "metadata": {},
   "source": [
    "# Evaluate Model with 10-Fold Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e98ec6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation RMSE scores: [10770.89696949 11866.81161686 13570.61634722 10503.98340738\n",
      " 11752.14093868 11182.40430438 10330.0457939  11471.28094777\n",
      " 10787.254567   12734.74982052]\n",
      "Mean Cross-Validation RMSE: 11497.02\n",
      "Standard Deviation of Cross-Validation RMSE: 975.31\n"
     ]
    }
   ],
   "source": [
    "# Perform 10-fold cross-validation\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "cross_val_scores = cross_val_score(final_pipeline, X, y, cv=kf, scoring='neg_mean_squared_error')\n",
    "cross_val_rmse_scores = np.sqrt(-cross_val_scores)\n",
    "\n",
    "print(f\"Cross-Validation RMSE scores: {cross_val_rmse_scores}\")\n",
    "print(f\"Mean Cross-Validation RMSE: {cross_val_rmse_scores.mean():.2f}\")\n",
    "print(f\"Standard Deviation of Cross-Validation RMSE: {cross_val_rmse_scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ae9ed0",
   "metadata": {},
   "source": [
    "In this section, we evaluate the model using 10-fold cross-validation and compute the average and standard deviation of the RMSE scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b985737",
   "metadata": {},
   "source": [
    "# Compute Feature Importance and Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d91327b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 most important grouped features with impact:\n",
      "Km: 14336.4312 (Positive)\n",
      "model: 8127.0920 (Positive)\n",
      "manufactor: 7697.3878 (Positive)\n",
      "Year: 7223.2378 (Positive)\n",
      "Engine_type: 4400.9205 (Positive)\n"
     ]
    }
   ],
   "source": [
    "# Get the preprocessor and model from the best pipeline\n",
    "preprocessor = final_pipeline.named_steps['preprocessor']\n",
    "elastic_net = final_pipeline.named_steps['model']\n",
    "\n",
    "# Preprocess the data\n",
    "X_processed = preprocessor.transform(X)\n",
    "\n",
    "# Get feature names after preprocessing\n",
    "onehot_feature_names = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names(categorical_features)\n",
    "feature_names = numerical_features + list(onehot_feature_names)\n",
    "\n",
    "# Feature importance for ElasticNet (coefficient magnitude)\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': np.abs(elastic_net.coef_)\n",
    "})\n",
    "\n",
    "# Create feature groups dictionary\n",
    "feature_groups = {}\n",
    "for feature in categorical_features:\n",
    "    dummies = [col for col in feature_names if col.startswith(feature)]\n",
    "    for dummy in dummies:\n",
    "        feature_groups[dummy] = feature\n",
    "\n",
    "# Group importances by taking the average\n",
    "grouped_importance = feature_importance.groupby(\n",
    "    feature_importance['feature'].map(lambda x: feature_groups.get(x, x))\n",
    ").mean().sort_values('importance', ascending=False)\n",
    "\n",
    "# Calculate impact\n",
    "grouped_importance['impact'] = 'Neutral'  # Default value\n",
    "\n",
    "for index in grouped_importance.index:\n",
    "    mask = feature_importance['feature'].map(lambda x: feature_groups.get(x, x)) == index\n",
    "    if mask.any():\n",
    "        relevant_features = feature_importance.loc[mask, 'feature']\n",
    "        relevant_coefs = [elastic_net.coef_[feature_names.index(feat)] for feat in relevant_features]\n",
    "        coef_sum = (feature_importance.loc[mask, 'importance'] * np.sign(relevant_coefs)).sum()\n",
    "        grouped_importance.loc[index, 'impact'] = 'Positive' if coef_sum >= 0 else 'Negative'\n",
    "\n",
    "print(\"\\nTop 5 most important grouped features with impact:\")\n",
    "for index, row in grouped_importance.head(5).iterrows():\n",
    "    feature = index\n",
    "    importance = row['importance']\n",
    "    impact = row['impact']\n",
    "    print(f\"{feature}: {importance:.4f} ({impact})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa54752",
   "metadata": {},
   "source": [
    "In this section, we compute the feature importance and their impact on the model, including grouped categorical features and their positive or negative impact. The OneHotEncoder has transformed categorical features into binary columns, and we combine the importance of these binary columns to determine the overall importance of each categorical feature group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f681143",
   "metadata": {},
   "source": [
    "# Make Predictions on Test Set and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a2c1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11300.86\n",
      "R-squared: 0.72\n",
      "Adjusted R-squared: 0.71\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = final_pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mape = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\n",
    "\n",
    "# Calculate Adjusted R-squared\n",
    "n = X_test.shape[0]\n",
    "p = X_test.shape[1]\n",
    "adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "print(f\"Adjusted R-squared: {adjusted_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf4f2bc",
   "metadata": {},
   "source": [
    "In this section, we make predictions on the test set, evaluate the model using various metrics (RMSE, R-squared), and calculate the adjusted R-squared value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3da3084",
   "metadata": {},
   "source": [
    "# Evaluate the Model on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ae95403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compare Training and Validation Errors:\n",
      "Training-\n",
      "Training RMSE: 8379.48\n",
      "Training R-squared: 0.86\n",
      "Training Adjusted R-squared: 0.85\n",
      "Training MAE: 6180.81\n",
      "Training MAPE: 15.01%\n",
      "Test-\n",
      "Test RMSE: 11300.86\n",
      "Test R-squared: 0.72\n",
      "Test Adjusted R-squared: 0.71\n",
      "Test MAE: 7843.02\n",
      "Test MAPE: 16.77%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "y_train_predictions = final_pipeline.predict(X_train)\n",
    "\n",
    "# Calculate training metrics\n",
    "train_root_mean_squared_error = np.sqrt(mean_squared_error(y_train, y_train_predictions))\n",
    "train_r_squared = r2_score(y_train, y_train_predictions)\n",
    "train_mean_absolute_error = mean_absolute_error(y_train, y_train_predictions)\n",
    "train_mean_absolute_percentage_error = np.mean(np.abs((y_train - y_train_predictions) / y_train)) * 100\n",
    "\n",
    "# Calculate Adjusted R-squared for training set\n",
    "num_train_samples = X_train.shape[0]\n",
    "num_train_features = X_train.shape[1]\n",
    "train_adjusted_r_squared = 1 - (1 - train_r_squared) * (num_train_samples - 1) / (num_train_samples - num_train_features - 1)\n",
    "\n",
    "# Print training metrics\n",
    "print(\"Compare Training and Validation Errors:\")\n",
    "print(\"Training-\")\n",
    "print(f\"Training RMSE: {train_root_mean_squared_error:.2f}\")\n",
    "print(f\"Training R-squared: {train_r_squared:.2f}\")\n",
    "print(f\"Training Adjusted R-squared: {train_adjusted_r_squared:.2f}\")\n",
    "print(f\"Training MAE: {train_mean_absolute_error:.2f}\")\n",
    "print(f\"Training MAPE: {train_mean_absolute_percentage_error:.2f}%\")\n",
    "\n",
    "# Print test metrics\n",
    "print(\"Test-\")\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R-squared: {r2:.2f}\")\n",
    "print(f\"Test Adjusted R-squared: {adjusted_r2:.2f}\")\n",
    "print(f\"Test MAE: {mae:.2f}\")\n",
    "print(f\"Test MAPE: {mape:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c4243",
   "metadata": {},
   "source": [
    "In this section, we evaluate the model's performance on the training set and calculate several metrics to compare the training and validation errors.\n",
    "\n",
    "Evaluate the model on the training set: We use the trained model to make predictions on the training data (X_train).\n",
    "\n",
    "Calculate training metrics: We calculate the following metrics for the training set:\n",
    "\n",
    "Root Mean Squared Error (RMSE): Measures the average magnitude of the errors between predicted and actual values.\n",
    "R-squared (R²): Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "Mean Absolute Error (MAE): Measures the average magnitude of the errors in a set of predictions, without considering their direction.\n",
    "Mean Absolute Percentage Error (MAPE): Measures the accuracy of a forecasting method in percentage terms.\n",
    "Calculate Adjusted R-squared for training set: Adjusted R-squared takes into account the number of predictors in the model, providing a more accurate measure when comparing models with different numbers of predictors.\n",
    "\n",
    "Print training metrics: We print the calculated metrics for the training set to compare with the validation (test) set.\n",
    "\n",
    "Print test metrics: We print the calculated metrics for the test set to compare with the training set metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb55d0c",
   "metadata": {},
   "source": [
    "We wanted to understand how well the data cleaning function and the model we created fit the \"real world\" - meaning how accurate the predictions of our test data are compared to our actual data and how well we cleaned our data in general, not just in a way that fits our specific data.\n",
    "\n",
    "Our goal was for our RMSE to be lower than the general RMSE and for our R-squared to be higher than the general R-squared. \n",
    "\n",
    "Unfortunately, while close, it is not better.\n",
    "\n",
    "We examined why this is the case and whether it is possible to achieve a better result. We realized that we can always tweak it a bit more, but it still won't reach the desired result because our data sample is very small. As the sample size increases, we can get closer to reality.\n",
    "\n",
    "We tried to get as close to reality as possible with the existing database and got relatively close!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a609767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
